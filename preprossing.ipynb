{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d11d14bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720f1469",
   "metadata": {},
   "source": [
    "# Get data from .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3983a70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"./data/hotel.json\"\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    hotels_list = json.load(file)\n",
    "\n",
    "print(len(hotels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c03674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are a data conversion assistant. Your task is to transform each Q&A pair into 6 diverse multi-turn conversations in ShareGPT fine-tuning format.\n",
    "\n",
    "Each input Q&A pair relates to a specific hotel. Your output must help the assistant learn to respond naturally and accurately for that **specific hotel**.\n",
    "\n",
    "For each input Q&A pair, generate 6 JSON objects. Each object represents a distinct conversation with:\n",
    "- 4 user questions and 4 assistant answers (8 messages in total).\n",
    "- The **first user question** in each conversation must explicitly mention the hotel name (e.g., “Renaissance Riverside”, “Khách sạn Mường Thanh”) in a natural and varied way.\n",
    "- Questions should ask the same core idea in different ways, using varied tone, length, and style (casual, formal, brief, detailed, etc.).\n",
    "- **Only one conversation** (out of the six) should include a general question about the hotel’s overall information (e.g., “Cho tôi thông tin khách sạn Renaissance Riverside”, “Nói cho tôi biết về khách sạn Mường Thanh”) and the answer is full description of the hotel.\n",
    "- **Only one different conversation** (out of the six) include a question asking specifically about the hotel’s location or address.\n",
    "\n",
    "- Assistant replies should convey the same meaning (i.e., the original answer), but phrased to match the tone and wording of each question.\n",
    "\n",
    "Each JSON object must follow the ShareGPT JSONL schema:\n",
    "- Must have a top-level field: `conversations`.\n",
    "- `conversations` is a list of 8 alternating messages.\n",
    "- Messages alternate between `{{\"from\": \"human\", \"value\": ...}}` and `{{\"from\": \"gpt\", \"value\": ...}}`.\n",
    "\n",
    "Output: a list of 6 JSON objects (no explanation, no extra text).\n",
    "\n",
    "Here is hotel's information:\n",
    "{hotel_information}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d685c9c9",
   "metadata": {},
   "source": [
    "## Send to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b24b070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI \n",
    "\n",
    "CLIENT = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENROUTER_API_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6957782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "def call_openrouter_api(prompt: str) -> str:\n",
    "    try:\n",
    "        completion = CLIENT.chat.completions.create(\n",
    "            model=\"qwen/qwen3-235b-a22b-2507:free\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return completion.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"API called failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_conversations(api_response: str) -> List[Dict]:\n",
    "    \"\"\"Get conversations in JSON type\"\"\"\n",
    "    if not api_response:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        conversations_data = json.loads(api_response)\n",
    "        return conversations_data\n",
    "        # return conversations_data.get('conversations', [])\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Failed to parse API response: {e}\")\n",
    "        return []\n",
    "\n",
    "def save_to_file(data: List[Dict], filename: str):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"[\")\n",
    "\n",
    "        for entry in data:\n",
    "            file.write(json.dumps(entry, ensure_ascii=False) + \",\\n\")\n",
    "\n",
    "        file.write(\"]\")\n",
    "        \n",
    "    print(f'Saved {len(data)} entries to {filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ea862",
   "metadata": {},
   "source": [
    "## Loop through each hotel JSON object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e36d6f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf40640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed succesfully hotel: 0 with 6 conversations\n",
      "Processed succesfully hotel: 1 with 6 conversations\n",
      "Processed succesfully hotel: 2 with 6 conversations\n",
      "Processed succesfully hotel: 3 with 6 conversations\n",
      "Processed succesfully hotel: 4 with 6 conversations\n",
      "Processed succesfully hotel: 5 with 6 conversations\n",
      "Processed succesfully hotel: 6 with 6 conversations\n",
      "Processed succesfully hotel: 7 with 6 conversations\n",
      "Processed succesfully hotel: 8 with 6 conversations\n",
      "Processed succesfully hotel: 9 with 6 conversations\n",
      "Waiting 3 minutes before continuing...\n",
      "Processed succesfully hotel: 10 with 6 conversations\n",
      "Processed succesfully hotel: 11 with 6 conversations\n",
      "Processed succesfully hotel: 12 with 6 conversations\n",
      "Processed succesfully hotel: 13 with 6 conversations\n",
      "Failed to parse API response: Expecting ',' delimiter: line 1 column 4162 (char 4161)\n",
      "Processed succesfully hotel: 14 with 0 conversations\n",
      "Processed succesfully hotel: 15 with 6 conversations\n",
      "Processed succesfully hotel: 16 with 6 conversations\n",
      "Processed succesfully hotel: 17 with 6 conversations\n",
      "Processed succesfully hotel: 18 with 6 conversations\n",
      "Processed succesfully hotel: 19 with 6 conversations\n"
     ]
    }
   ],
   "source": [
    "list_conversations = []\n",
    "\n",
    "for index, hotel in enumerate(hotels_list):\n",
    "    prompt = PROMPT_TEMPLATE.format(hotel_information=str(hotel))\n",
    "    response = call_openrouter_api(prompt)\n",
    "\n",
    "    hotel_conversations = extract_conversations(response)\n",
    "    print(f\"Processed succesfully hotel: {index} with {len(hotel_conversations)} conversations\")\n",
    "\n",
    "    list_conversations += hotel_conversations\n",
    "\n",
    "    if (index + 1) % 10 == 0 and (index + 1) < len(hotels_list):\n",
    "        print(\"Waiting 3 minutes before continuing...\")\n",
    "        time.sleep(180)  # 180 giây = 3 phút"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c8d5026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 114 entries to test.json\n"
     ]
    }
   ],
   "source": [
    "save_to_file(list_conversations, 'test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0517686",
   "metadata": {},
   "source": [
    "## Push to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c1fb060",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tyan\\Quickom\\Simple-Fine-Tune-Llama\\finetune_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6d5d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import json\n",
    "\n",
    "with open(\"test.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "dataset = Dataset.from_list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7b98ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepoUrl('https://huggingface.co/datasets/tyanfarm/hotel_conversations_118', endpoint='https://huggingface.co', repo_type='dataset', repo_id='tyanfarm/hotel_conversations_118')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "dataset_name = \"tyanfarm/hotel_conversations_118\"\n",
    "api = HfApi()\n",
    "api.create_repo(repo_id=dataset_name, repo_type=\"dataset\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efcf696e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<?, ?ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.73s/ shards]\n",
      "d:\\Tyan\\Quickom\\Simple-Fine-Tune-Llama\\finetune_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Tyan\\.cache\\huggingface\\hub\\datasets--tyanfarm--hotel_conversations_118. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/tyanfarm/hotel_conversations_118/commit/c27af2666d04309771c90a4313310877808b3382', commit_message='Upload dataset', commit_description='', oid='c27af2666d04309771c90a4313310877808b3382', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/tyanfarm/hotel_conversations_118', endpoint='https://huggingface.co', repo_type='dataset', repo_id='tyanfarm/hotel_conversations_118'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(dataset_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
