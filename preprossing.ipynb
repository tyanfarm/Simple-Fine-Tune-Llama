{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d14bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720f1469",
   "metadata": {},
   "source": [
    "# Get data from .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3983a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"./data/hotel.json\"\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    hotels_list = json.load(file)\n",
    "\n",
    "print(len(hotels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c03674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are a data conversion assistant. Your task is to transform each Q&A pair into 6 diverse multi-turn conversations in ShareGPT fine-tuning format.\n",
    "\n",
    "Each input Q&A pair relates to a specific hotel. Your output must help the assistant learn to respond naturally and accurately for that **specific hotel**.\n",
    "\n",
    "For each input Q&A pair, generate 6 JSON objects. Each object represents a distinct conversation with:\n",
    "- 4 user questions and 4 assistant answers (8 messages in total).\n",
    "- The **first user question** in each conversation must explicitly mention the hotel name (e.g., “Renaissance Riverside”, “Khách sạn Mường Thanh”) in a natural and varied way.\n",
    "- Questions should ask the same core idea in different ways, using varied tone, length, and style (casual, formal, brief, detailed, etc.).\n",
    "- **Only one conversation** (out of the six) should include a general question about the hotel’s overall information (e.g., “Cho tôi thông tin khách sạn Renaissance Riverside”, “Nói cho tôi biết về khách sạn Mường Thanh”) and the answer is full description of the hotel.\n",
    "- **Only one different conversation** (out of the six) include a question asking specifically about the hotel’s location or address.\n",
    "\n",
    "- Assistant replies should convey the same meaning (i.e., the original answer), but phrased to match the tone and wording of each question.\n",
    "\n",
    "Each JSON object must follow the ShareGPT JSONL schema:\n",
    "- Must have a top-level field: `conversations`.\n",
    "- `conversations` is a list of 8 alternating messages.\n",
    "- Messages alternate between `{{\"from\": \"human\", \"value\": ...}}` and `{{\"from\": \"gpt\", \"value\": ...}}`.\n",
    "\n",
    "Output: a list of 6 JSON objects (no explanation, no extra text).\n",
    "\n",
    "Here is hotel's information:\n",
    "{hotel_information}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d685c9c9",
   "metadata": {},
   "source": [
    "## Send to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI \n",
    "\n",
    "CLIENT = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENROUTER_API_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6957782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "def call_openrouter_api(prompt: str) -> str:\n",
    "    try:\n",
    "        completion = CLIENT.chat.completions.create(\n",
    "            model=\"qwen/qwen3-235b-a22b-2507:free\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return completion.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"API called failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_conversations(api_response: str) -> List[Dict]:\n",
    "    \"\"\"Get conversations in JSON type\"\"\"\n",
    "    if not api_response:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        conversations_data = json.loads(api_response)\n",
    "        return conversations_data\n",
    "        # return conversations_data.get('conversations', [])\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Failed to parse API response: {e}\")\n",
    "        return []\n",
    "\n",
    "def save_to_file(data: List[Dict], filename: str):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        for entry in data:\n",
    "            file.write(json.dumps(entry, ensure_ascii=False) + \",\\n\")\n",
    "    print(f'Saved {len(data)} entries to {filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ea862",
   "metadata": {},
   "source": [
    "## Loop through each hotel JSON object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf40640",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_conversations = []\n",
    "\n",
    "for index, hotel in enumerate(hotels_list):\n",
    "    prompt = PROMPT_TEMPLATE.format(hotel_information=str(hotel))\n",
    "    response = call_openrouter_api(prompt)\n",
    "\n",
    "    hotel_conversations = extract_conversations(response)\n",
    "    print(f\"Processed succesfully hotel: {index} with {len(hotel_conversations)} conversations\")\n",
    "\n",
    "    list_conversations += hotel_conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d5026",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_file(list_conversations, 'test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0517686",
   "metadata": {},
   "source": [
    "## Push to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1fb060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d5d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import json\n",
    "\n",
    "with open(\"test.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "dataset = Dataset.from_list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b98ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "dataset_name = \"tyanfarm/hotel_conversations_118\"\n",
    "api = HfApi()\n",
    "api.create_repo(repo_id=dataset_name, repo_type=\"dataset\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcf696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.push_to_hub(dataset_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
