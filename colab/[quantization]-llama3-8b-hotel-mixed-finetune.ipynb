{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4jtRlNZp1NNg"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os, re\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
        "    xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
        "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "!pip install transformers==4.55.4\n",
        "!pip install --no-deps trl==0.22.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aX3uY8bD3HUT"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"tyanfarm/llama3-8b-hotels-information-mixed-5epochs-finetuned\", #model folder\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")\n",
        "FastLanguageModel.for_inference(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DJOtEqEY3NXo"
      },
      "outputs": [],
      "source": [
        "# model.save_pretrained_merged(\"tyanfarm/llama3-8b-hotel-addresses-finetuned-gguf\", tokenizer, save_method = \"merged_16bit\",)\n",
        "model.save_pretrained_gguf(\"tyanfarm/llama3-8b-hotel-information-mixed-finetuned-gguf\", tokenizer, quantization_method=\"q8_0\",)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq307AbR3fYB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "68CusBWr3fnb"
      },
      "outputs": [],
      "source": [
        "model.push_to_hub_gguf(\n",
        "        \"tyanfarm/llama3-8b-hotel-information-mixed-finetuned-gguf\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q8_0\"],\n",
        "        # quantization_method = [\"q4_k_m\"],\n",
        "        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP3AQ9rRrMm9"
      },
      "outputs": [],
      "source": [
        "chat_prompt = \"\"\"\n",
        "### Instruction\n",
        "{}\n",
        "\n",
        "### Input\n",
        "{}\n",
        "\n",
        "### Response\n",
        "{}\"\"\"\n",
        "\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    chat_prompt.format(\n",
        "        \"\", # instruction - leave this blank!\n",
        "        \"Renaissance Riverside Saigon Hotel ở đâu vậy\", # input\n",
        "        \"\", # output - leave this blank!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=512,\n",
        "    temperature=0.5,\n",
        "    top_k=10,\n",
        "    top_p=0.95)\n",
        "decoded_output = tokenizer.batch_decode(outputs)[0]\n",
        "tokenizer.batch_decode(outputs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
